Train auc:0.832202, f1:0.782774, aupr:0.836037, precision:0.808025, recall:0.759054
Dev auc:0.967846, f1:0.910714, aupr:0.975492, precision:0.930091, recall:0.892128
Test auc:0.971987, f1:0.918138, aupr:0.973002, precision:0.928571, recall:0.907937
epoch1 loss:199.26231290635457
Train auc:0.983563, f1:0.943757, aupr:0.984461, precision:0.957763, recall:0.930155
Dev auc:0.988024, f1:0.948949, aupr:0.990737, precision:0.978328, recall:0.921283
Test auc:0.991334, f1:0.949429, aupr:0.992371, precision:0.97651, recall:0.92381
epoch2 loss:56.98697895020063
Train auc:0.993806, f1:0.969325, aupr:0.993756, precision:0.975309, recall:0.963415
Dev auc:0.984814, f1:0.945559, aupr:0.987883, precision:0.929577, recall:0.962099
Test auc:0.988667, f1:0.943511, aupr:0.988614, precision:0.908824, recall:0.980952
epoch3 loss:32.50741534179019
Train auc:0.997322, f1:0.984604, aupr:0.997536, precision:0.988454, recall:0.980783
Dev auc:0.979162, f1:0.91678, aupr:0.983636, precision:0.861538, recall:0.979592
Test auc:0.98484, f1:0.915805, aupr:0.984613, precision:0.856354, recall:0.984127
epoch4 loss:19.594796103071044
Train auc:0.997244, f1:0.985577, aupr:0.996662, precision:0.986306, recall:0.984848
Dev auc:0.985916, f1:0.960584, aupr:0.989846, precision:0.961988, recall:0.959184
Test auc:0.988884, f1:0.949045, aupr:0.990299, precision:0.952077, recall:0.946032
epoch5 loss:28.791273269710864
Train auc:0.998342, f1:0.991128, aupr:0.998156, precision:0.991494, recall:0.990761
Dev auc:0.975617, f1:0.921379, aupr:0.979716, precision:0.874346, recall:0.973761
Test auc:0.984375, f1:0.921687, aupr:0.98712, precision:0.876791, recall:0.971429
epoch6 loss:14.33102445303904
Train auc:0.999469, f1:0.994826, aupr:0.999544, precision:0.994826, recall:0.994826
Dev auc:0.981228, f1:0.952104, aupr:0.985715, precision:0.947977, recall:0.956268
Test auc:0.985585, f1:0.948195, aupr:0.98796, precision:0.937888, recall:0.95873
epoch7 loss:7.2953983033175955
Train auc:0.999844, f1:0.995008, aupr:0.99987, precision:0.99556, recall:0.994457
Dev auc:0.983378, f1:0.954074, aupr:0.987449, precision:0.96988, recall:0.938776
Test auc:0.987601, f1:0.951768, aupr:0.990365, precision:0.964169, recall:0.939683
epoch8 loss:5.687933478089402
Train auc:0.999946, f1:0.998707, aupr:0.999954, precision:0.998154, recall:0.999261
Dev auc:0.982308, f1:0.95421, aupr:0.986399, precision:0.967066, recall:0.941691
Test auc:0.988015, f1:0.949919, aupr:0.990465, precision:0.967105, recall:0.933333
epoch9 loss:2.9305327213953736
Train auc:0.999987, f1:0.999446, aupr:0.999989, precision:0.999261, recall:0.99963
Dev auc:0.982874, f1:0.952802, aupr:0.987128, precision:0.964179, recall:0.941691
Test auc:0.987302, f1:0.951613, aupr:0.989818, precision:0.967213, recall:0.936508
epoch10 loss:2.015652932744576
Train auc:0.999996, f1:0.99963, aupr:0.999997, precision:0.99963, recall:0.99963
Dev auc:0.982088, f1:0.951542, aupr:0.986667, precision:0.95858, recall:0.944606
Test auc:0.986009, f1:0.950241, aupr:0.988385, precision:0.961039, recall:0.939683
epoch11 loss:1.4852363172582783
Train auc:0.999996, f1:0.99963, aupr:0.999997, precision:0.99963, recall:0.99963
Dev auc:0.981742, f1:0.951542, aupr:0.986308, precision:0.95858, recall:0.944606
Test auc:0.985719, f1:0.948718, aupr:0.98793, precision:0.957929, recall:0.939683
epoch12 loss:1.1963089347712033
Train auc:0.999998, f1:0.999815, aupr:0.999998, precision:1.0, recall:0.99963
Dev auc:0.981584, f1:0.951684, aupr:0.986099, precision:0.955882, recall:0.947522
Test auc:0.985668, f1:0.948718, aupr:0.987618, precision:0.957929, recall:0.939683
epoch13 loss:1.0934847490433075
Train auc:0.999998, f1:0.999815, aupr:0.999998, precision:1.0, recall:0.99963
Dev auc:0.981448, f1:0.951684, aupr:0.986006, precision:0.955882, recall:0.947522
Test auc:0.985626, f1:0.948718, aupr:0.987486, precision:0.957929, recall:0.939683
epoch14 loss:0.9753670955501419
Train auc:0.999998, f1:0.999815, aupr:0.999999, precision:1.0, recall:0.99963
Dev auc:0.981521, f1:0.951684, aupr:0.986103, precision:0.955882, recall:0.947522
Test auc:0.985533, f1:0.948718, aupr:0.987369, precision:0.957929, recall:0.939683
epoch15 loss:0.9165192193601954
Train auc:0.999997, f1:0.999815, aupr:0.999998, precision:1.0, recall:0.99963
Dev auc:0.981401, f1:0.950292, aupr:0.985955, precision:0.953079, recall:0.947522
Test auc:0.985502, f1:0.948718, aupr:0.987166, precision:0.957929, recall:0.939683
epoch16 loss:0.8429095881062691
Train auc:0.999998, f1:0.999815, aupr:0.999999, precision:1.0, recall:0.99963
Dev auc:0.981459, f1:0.950292, aupr:0.986028, precision:0.953079, recall:0.947522
Test auc:0.985585, f1:0.948718, aupr:0.987243, precision:0.957929, recall:0.939683
epoch17 loss:0.7804096091105244
Train auc:0.999999, f1:0.999815, aupr:0.999999, precision:1.0, recall:0.99963
Dev auc:0.98149, f1:0.951684, aupr:0.986024, precision:0.955882, recall:0.947522
Test auc:0.985668, f1:0.948718, aupr:0.987314, precision:0.957929, recall:0.939683
epoch18 loss:0.7181379575040432
Train auc:0.999999, f1:0.999815, aupr:0.999999, precision:1.0, recall:0.99963
Dev auc:0.981348, f1:0.950292, aupr:0.98589, precision:0.953079, recall:0.947522
Test auc:0.985404, f1:0.948718, aupr:0.986946, precision:0.957929, recall:0.939683
epoch19 loss:0.6976284957733023
Train auc:0.999998, f1:0.999815, aupr:0.999999, precision:1.0, recall:0.99963
Dev auc:0.981501, f1:0.951684, aupr:0.986018, precision:0.955882, recall:0.947522
Test auc:0.985378, f1:0.948718, aupr:0.986911, precision:0.957929, recall:0.939683
epoch20 loss:0.6687722991637277
Finally test result of auc:0.991334, f1:0.949429, aupr:0.992371, precision:0.97651, recall:0.92381
Train auc:0.892843, f1:0.85032, aupr:0.92403, precision:0.86562, recall:0.835551
Dev auc:0.967705, f1:0.939794, aupr:0.977298, precision:0.946746, recall:0.932945
Test auc:0.959785, f1:0.928685, aupr:0.966511, precision:0.927215, recall:0.930159
epoch1 loss:239.5411313478452
Train auc:0.981489, f1:0.957558, aupr:0.983752, precision:0.964741, recall:0.95048
Dev auc:0.98557, f1:0.968208, aupr:0.990748, precision:0.959885, recall:0.976676
Test auc:0.992503, f1:0.963665, aupr:0.99388, precision:0.959119, recall:0.968254
epoch2 loss:69.31914546091205
Train auc:0.893957, f1:0.849444, aupr:0.925517, precision:0.86659, recall:0.832964
Dev auc:0.963116, f1:0.90611, aupr:0.970418, precision:0.926829, recall:0.886297
Test auc:0.957184, f1:0.909667, aupr:0.962733, precision:0.908228, recall:0.911111
epoch1 loss:243.29460612740235
Train auc:0.993295, f1:0.972217, aupr:0.995096, precision:0.981182, recall:0.963415
Dev auc:0.984867, f1:0.965116, aupr:0.990199, precision:0.962319, recall:0.96793
Test auc:0.995212, f1:0.965732, aupr:0.996215, precision:0.948012, recall:0.984127
epoch3 loss:30.356049156885895
Train auc:0.99807, f1:0.987576, aupr:0.998322, precision:0.991068, recall:0.984109
Dev auc:0.98923, f1:0.963504, aupr:0.992786, precision:0.964912, recall:0.962099
Test auc:0.993868, f1:0.973144, aupr:0.995665, precision:0.968553, recall:0.977778
epoch4 loss:16.29233626204507
Train auc:0.999508, f1:0.991665, aupr:0.999595, precision:0.994059, recall:0.989283
Dev auc:0.990268, f1:0.964706, aupr:0.993569, precision:0.973294, recall:0.956268
Test auc:0.993299, f1:0.979332, aupr:0.9953, precision:0.980892, recall:0.977778
epoch5 loss:9.621905226004868
Train auc:0.9998, f1:0.996299, aupr:0.999825, precision:0.997776, recall:0.994826
Dev auc:0.989009, f1:0.963181, aupr:0.99288, precision:0.973214, recall:0.953353
Test auc:0.993868, f1:0.972973, aupr:0.995447, precision:0.974522, recall:0.971429
epoch6 loss:6.278764273136304
Train auc:0.893274, f1:0.847254, aupr:0.92353, precision:0.862835, recall:0.832225
Dev auc:0.968072, f1:0.928675, aupr:0.979388, precision:0.927326, recall:0.930029
Test auc:0.965658, f1:0.931034, aupr:0.970292, precision:0.919505, recall:0.942857
epoch1 loss:248.68916285389392
Train auc:0.999263, f1:0.995194, aupr:0.999489, precision:0.995562, recall:0.994826
Dev auc:0.988611, f1:0.961988, aupr:0.992539, precision:0.964809, recall:0.959184
Test auc:0.993671, f1:0.974684, aupr:0.995321, precision:0.971609, recall:0.977778
epoch7 loss:7.767533710340846
Train auc:0.979969, f1:0.951224, aupr:0.982223, precision:0.962193, recall:0.940503
Dev auc:0.984468, f1:0.965217, aupr:0.989132, precision:0.959654, recall:0.970845
Test auc:0.990652, f1:0.957746, aupr:0.992481, precision:0.944444, recall:0.971429
epoch2 loss:78.36636340896126
Train auc:0.99993, f1:0.997228, aupr:0.999941, precision:0.997412, recall:0.997044
Dev auc:0.986419, f1:0.965825, aupr:0.991635, precision:0.984848, recall:0.947522
Test auc:0.992503, f1:0.967638, aupr:0.994518, precision:0.986799, recall:0.949206
epoch8 loss:3.5017633968974957
Train auc:0.993188, f1:0.975074, aupr:0.995032, precision:0.981648, recall:0.968588
Dev auc:0.984835, f1:0.96361, aupr:0.990454, precision:0.962209, recall:0.965015
Test auc:0.990424, f1:0.95679, aupr:0.993369, precision:0.930931, recall:0.984127
epoch3 loss:30.330541618363167
Train auc:0.999958, f1:0.998707, aupr:0.999964, precision:0.998522, recall:0.998891
Dev auc:0.987174, f1:0.962963, aupr:0.991842, precision:0.978916, recall:0.947522
Test auc:0.992793, f1:0.967846, aupr:0.99476, precision:0.980456, recall:0.955556
epoch9 loss:2.371535554680927
Train auc:0.99606, f1:0.987586, aupr:0.995983, precision:0.990338, recall:0.984848
Dev auc:0.9916, f1:0.96793, aupr:0.994278, precision:0.96793, recall:0.96793
Test auc:0.99333, f1:0.968454, aupr:0.994257, precision:0.962382, recall:0.974603
epoch4 loss:27.41895080217153
Train auc:0.999989, f1:0.998523, aupr:0.999991, precision:0.997786, recall:0.999261
Dev auc:0.988328, f1:0.963181, aupr:0.992411, precision:0.973214, recall:0.953353
Test auc:0.993258, f1:0.9728, aupr:0.995135, precision:0.980645, recall:0.965079
epoch10 loss:1.8190014970366652
Train auc:0.998126, f1:0.990748, aupr:0.998326, precision:0.992216, recall:0.989283
Dev auc:0.99226, f1:0.971014, aupr:0.994913, precision:0.965418, recall:0.976676
Test auc:0.992606, f1:0.972973, aupr:0.993669, precision:0.974522, recall:0.971429
epoch5 loss:14.351405497648532
Train auc:0.999879, f1:0.998892, aupr:0.999917, precision:0.998523, recall:0.999261
Dev auc:0.986482, f1:0.960352, aupr:0.991439, precision:0.967456, recall:0.953353
Test auc:0.993289, f1:0.976153, aupr:0.994775, precision:0.977707, recall:0.974603
epoch11 loss:2.1491902298134287
Train auc:0.999694, f1:0.994817, aupr:0.999727, precision:0.996662, recall:0.992979
Dev auc:0.987279, f1:0.970588, aupr:0.991518, precision:0.979228, recall:0.962099
Test auc:0.988739, f1:0.975923, aupr:0.992642, precision:0.987013, recall:0.965079
epoch6 loss:6.869566812845928
Train auc:1.0, f1:0.999815, aupr:1.0, precision:0.999631, recall:1.0
Dev auc:0.986555, f1:0.960352, aupr:0.991411, precision:0.967456, recall:0.953353
Test auc:0.993439, f1:0.976153, aupr:0.994859, precision:0.977707, recall:0.974603
epoch12 loss:0.7741985323063005
Train auc:0.999584, f1:0.995562, aupr:0.999665, precision:0.996299, recall:0.994826
Dev auc:0.989513, f1:0.969072, aupr:0.993329, precision:0.979167, recall:0.959184
Test auc:0.991986, f1:0.9728, aupr:0.994202, precision:0.980645, recall:0.965079
epoch7 loss:6.790720410392645
Train auc:1.0, f1:0.999815, aupr:1.0, precision:0.999631, recall:1.0
Dev auc:0.98665, f1:0.960352, aupr:0.99146, precision:0.967456, recall:0.953353
Test auc:0.993516, f1:0.972973, aupr:0.994984, precision:0.974522, recall:0.971429
epoch13 loss:0.6973133895894641
Train auc:0.999964, f1:0.998152, aupr:0.99997, precision:0.998521, recall:0.997783
Dev auc:0.990163, f1:0.970501, aupr:0.993733, precision:0.98209, recall:0.959184
Test auc:0.992906, f1:0.970968, aupr:0.994987, precision:0.986885, recall:0.955556
epoch8 loss:3.141044333229004
Train auc:1.0, f1:1.0, aupr:1.0, precision:1.0, recall:1.0
Dev auc:0.986702, f1:0.960352, aupr:0.991488, precision:0.967456, recall:0.953353
Test auc:0.993506, f1:0.971338, aupr:0.994931, precision:0.974441, recall:0.968254
epoch14 loss:0.6210868699917516
Train auc:0.999953, f1:0.998338, aupr:0.99996, precision:0.997785, recall:0.998891
Dev auc:0.989607, f1:0.969163, aupr:0.99336, precision:0.976331, recall:0.962099
Test auc:0.993082, f1:0.972713, aupr:0.995133, precision:0.983766, recall:0.961905
epoch9 loss:2.6563844165183985
Train auc:1.0, f1:1.0, aupr:1.0, precision:1.0, recall:1.0
Dev auc:0.986576, f1:0.960352, aupr:0.991417, precision:0.967456, recall:0.953353
Test auc:0.993289, f1:0.969697, aupr:0.994715, precision:0.974359, recall:0.965079
epoch15 loss:0.5303841195991135
Train auc:0.999991, f1:0.999076, aupr:0.999993, precision:0.998892, recall:0.999261
Dev auc:0.990037, f1:0.965015, aupr:0.993556, precision:0.965015, recall:0.965015
Test auc:0.992668, f1:0.972973, aupr:0.994724, precision:0.974522, recall:0.971429
epoch10 loss:1.7612467797823181
Train auc:1.0, f1:1.0, aupr:1.0, precision:1.0, recall:1.0
Dev auc:0.986608, f1:0.960352, aupr:0.991417, precision:0.967456, recall:0.953353
Test auc:0.993382, f1:0.971338, aupr:0.99478, precision:0.974441, recall:0.968254
epoch16 loss:0.5018445195024679
Train auc:0.999998, f1:0.999077, aupr:0.999998, precision:0.998523, recall:0.99963
Dev auc:0.990551, f1:0.96361, aupr:0.993818, precision:0.962209, recall:0.965015
Test auc:0.992948, f1:0.971429, aupr:0.994727, precision:0.971429, recall:0.971429
epoch11 loss:1.2749815772113209
Train auc:1.0, f1:1.0, aupr:1.0, precision:1.0, recall:1.0
Dev auc:0.986566, f1:0.961765, aupr:0.991415, precision:0.970326, recall:0.953353
Test auc:0.99333, f1:0.969793, aupr:0.994723, precision:0.971338, recall:0.968254
epoch17 loss:0.4609973827554157
Train auc:1.0, f1:1.0, aupr:1.0, precision:1.0, recall:1.0
Dev auc:0.990268, f1:0.966423, aupr:0.993674, precision:0.967836, recall:0.965015
Test auc:0.992751, f1:0.971429, aupr:0.994524, precision:0.971429, recall:0.971429
epoch12 loss:0.7486112417854738
Train auc:1.0, f1:1.0, aupr:1.0, precision:1.0, recall:1.0
Dev auc:0.986639, f1:0.961765, aupr:0.991465, precision:0.970326, recall:0.953353
Test auc:0.993299, f1:0.969793, aupr:0.994708, precision:0.971338, recall:0.968254
epoch18 loss:0.4247525762027782
Train auc:1.0, f1:1.0, aupr:1.0, precision:1.0, recall:1.0
Dev auc:0.990289, f1:0.96361, aupr:0.993644, precision:0.962209, recall:0.965015
Test auc:0.992679, f1:0.969889, aupr:0.99446, precision:0.968354, recall:0.971429
epoch13 loss:0.6662880502051349
Train auc:1.0, f1:1.0, aupr:1.0, precision:1.0, recall:1.0
Dev auc:0.986681, f1:0.961765, aupr:0.991474, precision:0.970326, recall:0.953353
Test auc:0.993341, f1:0.969793, aupr:0.994756, precision:0.971338, recall:0.968254
epoch19 loss:0.38012852233010985
Train auc:1.0, f1:1.0, aupr:1.0, precision:1.0, recall:1.0
Dev auc:0.990404, f1:0.966423, aupr:0.993734, precision:0.967836, recall:0.965015
Test auc:0.992772, f1:0.969889, aupr:0.994558, precision:0.968354, recall:0.971429
epoch14 loss:0.6049900699819983
Train auc:1.0, f1:1.0, aupr:1.0, precision:1.0, recall:1.0
Dev auc:0.986513, f1:0.960352, aupr:0.99135, precision:0.967456, recall:0.953353
Test auc:0.993299, f1:0.969793, aupr:0.994722, precision:0.971338, recall:0.968254
epoch20 loss:0.3585415515361112
Finally test result of auc:0.993299, f1:0.979332, aupr:0.9953, precision:0.980892, recall:0.977778
Train auc:0.963271, f1:0.927796, aupr:0.968906, precision:0.939394, recall:0.916482
Dev auc:0.982895, f1:0.937677, aupr:0.987843, precision:0.911846, recall:0.965015
Test auc:0.983124, f1:0.898678, aupr:0.986479, precision:0.836066, recall:0.971429
epoch1 loss:98.29489885513551
Train auc:0.963173, f1:0.928197, aupr:0.969129, precision:0.93944, recall:0.917221
Dev auc:0.9873, f1:0.934813, aupr:0.991055, precision:0.891534, recall:0.982507
Test auc:0.98907, f1:0.897547, aupr:0.99108, precision:0.822751, recall:0.987302
epoch1 loss:98.40187812919494
Train auc:0.989484, f1:0.970227, aupr:0.991397, precision:0.977136, recall:0.963415
Dev auc:0.991222, f1:0.979532, aupr:0.995122, precision:0.982405, recall:0.976676
Test auc:0.99637, f1:0.974922, aupr:0.997461, precision:0.962848, recall:0.987302
epoch2 loss:40.06581286404902
Finally test result of auc:0.99637, f1:0.974922, aupr:0.997461, precision:0.962848, recall:0.987302
Train auc:0.962972, f1:0.927796, aupr:0.968782, precision:0.939394, recall:0.916482
Dev auc:0.985591, f1:0.936886, aupr:0.989627, precision:0.902703, recall:0.973761
Test auc:0.984582, f1:0.897661, aupr:0.987782, precision:0.831978, recall:0.974603
epoch1 loss:98.71637335539755
Train auc:0.989511, f1:0.969449, aupr:0.991379, precision:0.977461, recall:0.961567
Dev auc:0.991296, f1:0.976812, aupr:0.995198, precision:0.971182, recall:0.982507
Test auc:0.995915, f1:0.971875, aupr:0.997154, precision:0.956923, recall:0.987302
epoch2 loss:40.93611341715902
Finally test result of auc:0.995915, f1:0.971875, aupr:0.997154, precision:0.956923, recall:0.987302
Train auc:0.963165, f1:0.928197, aupr:0.969149, precision:0.93944, recall:0.917221
Dev auc:0.987185, f1:0.933518, aupr:0.990962, precision:0.889182, recall:0.982507
Test auc:0.988915, f1:0.897547, aupr:0.990945, precision:0.822751, recall:0.987302
epoch1 loss:98.36070530356186
Train auc:0.989404, f1:0.969279, aupr:0.991426, precision:0.976735, recall:0.961936
Dev auc:0.991233, f1:0.975398, aupr:0.99516, precision:0.968391, recall:0.982507
Test auc:0.996391, f1:0.970543, aupr:0.997509, precision:0.948485, recall:0.993651
epoch2 loss:40.300365590486436
Train auc:0.996, f1:0.983454, aupr:0.99685, precision:0.989525, recall:0.977458
Dev auc:0.991411, f1:0.979592, aupr:0.995212, precision:0.979592, recall:0.979592
Test auc:0.997539, f1:0.981132, aupr:0.998043, precision:0.971963, recall:0.990476
epoch3 loss:22.63047126901779
Train auc:0.997856, f1:0.988327, aupr:0.998204, precision:0.991081, recall:0.985588
Dev auc:0.992229, f1:0.980966, aupr:0.995584, precision:0.985294, recall:0.976676
Test auc:0.99787, f1:0.981073, aupr:0.998254, precision:0.974922, recall:0.987302
epoch4 loss:15.838248685515062
Train auc:0.998985, f1:0.992968, aupr:0.999075, precision:0.99444, recall:0.9915
Dev auc:0.989922, f1:0.96861, aupr:0.994373, precision:0.993865, recall:0.944606
Test auc:0.997673, f1:0.984026, aupr:0.997993, precision:0.990354, recall:0.977778
epoch5 loss:10.507472982326252
Train auc:0.999418, f1:0.995932, aupr:0.999334, precision:0.996669, recall:0.995196
Dev auc:0.989607, f1:0.971684, aupr:0.994157, precision:0.993902, recall:0.950437
Test auc:0.997839, f1:0.980769, aupr:0.99808, precision:0.990291, recall:0.971429
epoch6 loss:6.771990737212523
Train auc:0.999487, f1:0.997598, aupr:0.999495, precision:0.997414, recall:0.997783
Dev auc:0.989251, f1:0.973214, aupr:0.993964, precision:0.993921, recall:0.953353
Test auc:0.998614, f1:0.984026, aupr:0.998774, precision:0.990354, recall:0.977778
epoch7 loss:5.933554415621742
Train auc:0.999752, f1:0.997967, aupr:0.999771, precision:0.998152, recall:0.997783
Dev auc:0.989911, f1:0.96861, aupr:0.994189, precision:0.993865, recall:0.944606
Test auc:0.998511, f1:0.979133, aupr:0.998654, precision:0.99026, recall:0.968254
epoch8 loss:4.39848965603956
Train auc:0.999667, f1:0.998522, aupr:0.99967, precision:0.998522, recall:0.998522
Dev auc:0.989314, f1:0.971768, aupr:0.993968, precision:0.990909, recall:0.953353
Test auc:0.998635, f1:0.987261, aupr:0.998792, precision:0.990415, recall:0.984127
epoch9 loss:3.674715945194554
Train auc:0.99978, f1:0.998522, aupr:0.999804, precision:0.998154, recall:0.998891
Dev auc:0.989387, f1:0.970238, aupr:0.993957, precision:0.990881, recall:0.950437
Test auc:0.998645, f1:0.985737, aupr:0.998759, precision:0.984177, recall:0.987302
epoch10 loss:2.9248452210659504
Train auc:0.999936, f1:0.999261, aupr:0.999944, precision:0.998892, recall:0.99963
Dev auc:0.989712, f1:0.973451, aupr:0.994095, precision:0.985075, recall:0.962099
Test auc:0.9988, f1:0.985737, aupr:0.998912, precision:0.984177, recall:0.987302
epoch11 loss:1.7603696686104944
Train auc:0.999988, f1:0.999815, aupr:0.99999, precision:0.999631, recall:1.0
Dev auc:0.989743, f1:0.973451, aupr:0.994122, precision:0.985075, recall:0.962099
Test auc:0.99878, f1:0.984127, aupr:0.998882, precision:0.984127, recall:0.984127
epoch12 loss:0.9243197328404253
Train auc:0.999997, f1:0.999815, aupr:0.999998, precision:0.999631, recall:1.0
Dev auc:0.989544, f1:0.974889, aupr:0.993998, precision:0.988024, recall:0.962099
Test auc:0.998728, f1:0.984127, aupr:0.998829, precision:0.984127, recall:0.984127
epoch13 loss:0.742709801862663
Train auc:1.0, f1:0.999815, aupr:1.0, precision:0.999631, recall:1.0
Dev auc:0.989523, f1:0.974889, aupr:0.993967, precision:0.988024, recall:0.962099
Test auc:0.998749, f1:0.984127, aupr:0.998849, precision:0.984127, recall:0.984127
epoch14 loss:0.5757206162217625
Train auc:1.0, f1:0.999815, aupr:1.0, precision:0.999631, recall:1.0
Dev auc:0.989502, f1:0.974889, aupr:0.993925, precision:0.988024, recall:0.962099
Test auc:0.998666, f1:0.982512, aupr:0.998768, precision:0.984076, recall:0.980952
epoch15 loss:0.5211729833973053
Train auc:1.0, f1:0.999815, aupr:1.0, precision:0.999631, recall:1.0
Dev auc:0.989513, f1:0.974889, aupr:0.993918, precision:0.988024, recall:0.962099
Test auc:0.998687, f1:0.982512, aupr:0.998786, precision:0.984076, recall:0.980952
epoch16 loss:0.4248948910442616
Train auc:1.0, f1:1.0, aupr:1.0, precision:1.0, recall:1.0
Dev auc:0.989628, f1:0.974889, aupr:0.993966, precision:0.988024, recall:0.962099
Test auc:0.998728, f1:0.982512, aupr:0.998822, precision:0.984076, recall:0.980952
epoch17 loss:0.38832451572421034
Train auc:1.0, f1:1.0, aupr:1.0, precision:1.0, recall:1.0
Dev auc:0.989502, f1:0.974889, aupr:0.993919, precision:0.988024, recall:0.962099
Test auc:0.99878, f1:0.982512, aupr:0.99887, precision:0.984076, recall:0.980952
epoch18 loss:0.3324071920029743
Train auc:1.0, f1:1.0, aupr:1.0, precision:1.0, recall:1.0
Dev auc:0.989418, f1:0.974889, aupr:0.993854, precision:0.988024, recall:0.962099
Test auc:0.998707, f1:0.982512, aupr:0.998804, precision:0.984076, recall:0.980952
epoch19 loss:0.31597449342266337
Train auc:1.0, f1:1.0, aupr:1.0, precision:1.0, recall:1.0
Dev auc:0.989555, f1:0.974889, aupr:0.993924, precision:0.988024, recall:0.962099
Test auc:0.998759, f1:0.982512, aupr:0.998847, precision:0.984076, recall:0.980952
epoch20 loss:0.26539815264626876
Finally test result of auc:0.99787, f1:0.981073, aupr:0.998254, precision:0.974922, recall:0.987302
